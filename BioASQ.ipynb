{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 22 15:51:12 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:84:00.0 Off |                    0 |\r\n",
      "| N/A   27C    P0    25W / 250W |      2MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b7b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet transformers==4.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d604b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet https://github.com/PyTorchLightning/pytorch-lightning/releases/download/1.2.6/pytorch-lightning-1.2.6.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7e8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet tokenizers==0.9.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6043e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet sentencepiece==0.1.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b19e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97aa54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown as gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from termcolor import colored\n",
    "import textwrap\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU's available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of GPU's available: \", len(physical_devices))\n",
    "\n",
    "if(len(physical_devices)>0):\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd09986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ee8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! unzip - bio-QA.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eafd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"BioASQ/BioASQ-train-factoid-4b.json\").open() as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cb64290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'version'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fe6b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BioASQ6b'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742e8075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f3ed067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paragraphs', 'title'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b6575b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BioASQ6b'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f23436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3266"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['data'][0]['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68358bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data['data'][0]['paragraphs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d48bde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qas': [{'id': '52bf208003868f1b06000019_002',\n",
       "   'question': 'What is the inheritance pattern of Li–Fraumeni syndrome?',\n",
       "   'answers': [{'text': 'autosomal dominant', 'answer_start': 213}]}],\n",
       " 'context': 'Balanced t(11;15)(q23;q15) in a TP53+/+ breast cancer patient from a Li-Fraumeni syndrome family. Li-Fraumeni Syndrome (LFS) is characterized by early-onset carcinogenesis involving multiple tumor types and shows autosomal dominant inheritance. Approximately 70% of LFS cases are due to germline mutations in the TP53 gene on chromosome 17p13.1. Mutations have also been found in the CHEK2 gene on chromosome 22q11, and others have been mapped to chromosome 11q23. While characterizing an LFS family with a documented defect in TP53, we found one family member who developed bilateral breast cancer at age 37 yet was homozygous for wild-type TP53. Her mother also developed early-onset primary bilateral breast cancer, and a sister had unilateral breast cancer and a soft tissue sarcoma. Cytogenetic analysis using fluorescence in situ hybridization of a primary skin fibroblast cell line revealed that the patient had a novel balanced reciprocal translocation between the long arms of chromosomes 11 and 15: t(11;15)(q23;q15). This translocation was not present in a primary skin fibroblast cell line from a brother with neuroblastoma, who was heterozygous for the TP53 mutation. There was no evidence of acute lymphoblastic leukemia in either the patient or her mother, although a nephew did develop leukemia and died in childhood. These data may implicate the region at breakpoint 11q23 and/or 15q15 as playing a significant role in predisposition to breast cancer development.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c703a71",
   "metadata": {},
   "outputs": [],
   "source": [
    " def extract_questions_and_answers(factoid_path = Path):\n",
    "    with factoid_path.open() as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    questions = data['data'][0]['paragraphs']\n",
    "     \n",
    "    data_rows = []\n",
    "    \n",
    "    for question in questions:\n",
    "        context = question['context']\n",
    "\n",
    "        for question_and_answers in question['qas']:\n",
    "            question = question_and_answers['question']\n",
    "            answers = question_and_answers['answers']\n",
    "\n",
    "            for answer in answers:\n",
    "                answer_text = answer['text']\n",
    "                answer_start = answer['answer_start']\n",
    "                answer_end = answer['answer_start'] + len(answer_text)\n",
    "                    \n",
    "                data_rows.append({\n",
    "                     \"question\" : question,\n",
    "                     \"context\"  : context,\n",
    "                     \"answer_text\" : answer_text,\n",
    "                     \"answer_start\" : answer_start,\n",
    "                     \"answer_end\" : answer_end\n",
    "                     })\n",
    "    return pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79ed2ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>213</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which type of lung cancer is afatinib used for?</td>\n",
       "      <td>Clinical perspective of afatinib in non-small ...</td>\n",
       "      <td>EGFR-mutant NSCLC</td>\n",
       "      <td>1203</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>419</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>Clinical and molecular characteristics of Pend...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>705</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the inheritance pattern of Li–Fraumeni...   \n",
       "1  What is the inheritance pattern of Li–Fraumeni...   \n",
       "2    Which type of lung cancer is afatinib used for?   \n",
       "3  Which hormone abnormalities are characteristic...   \n",
       "4  Which hormone abnormalities are characteristic...   \n",
       "\n",
       "                                             context         answer_text  \\\n",
       "0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant   \n",
       "1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n",
       "2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n",
       "3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n",
       "4  Clinical and molecular characteristics of Pend...             thyroid   \n",
       "\n",
       "   answer_start  answer_end  \n",
       "0           213         231  \n",
       "1           105         123  \n",
       "2          1203        1220  \n",
       "3           419         426  \n",
       "4           705         712  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_questions_and_answers(Path(\"BioASQ/BioASQ-train-factoid-4b.json\")).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97477a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('BioASQ/BioASQ-train-factoid-4b.json'),\n",
       " PosixPath('BioASQ/BioASQ-train-factoid-5b.json'),\n",
       " PosixPath('BioASQ/BioASQ-train-factoid-6b.json')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factoid_paths = sorted(list(Path(\"BioASQ/\").glob(\"BioASQ-train-*\")))\n",
    "factoid_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114f80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for factoid_path in factoid_paths:\n",
    "    dfs.append(extract_questions_and_answers(factoid_path))\n",
    "    \n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f181918f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Balanced t(11;15)(q23;q15) in a TP53+/+ breast...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>213</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the inheritance pattern of Li–Fraumeni...</td>\n",
       "      <td>Genetic modeling of Li-Fraumeni syndrome in ze...</td>\n",
       "      <td>autosomal dominant</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which type of lung cancer is afatinib used for?</td>\n",
       "      <td>Clinical perspective of afatinib in non-small ...</td>\n",
       "      <td>EGFR-mutant NSCLC</td>\n",
       "      <td>1203</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>DOCA sensitive pendrin expression in kidney, h...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>419</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which hormone abnormalities are characteristic...</td>\n",
       "      <td>Clinical and molecular characteristics of Pend...</td>\n",
       "      <td>thyroid</td>\n",
       "      <td>705</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the inheritance pattern of Li–Fraumeni...   \n",
       "1  What is the inheritance pattern of Li–Fraumeni...   \n",
       "2    Which type of lung cancer is afatinib used for?   \n",
       "3  Which hormone abnormalities are characteristic...   \n",
       "4  Which hormone abnormalities are characteristic...   \n",
       "\n",
       "                                             context         answer_text  \\\n",
       "0  Balanced t(11;15)(q23;q15) in a TP53+/+ breast...  autosomal dominant   \n",
       "1  Genetic modeling of Li-Fraumeni syndrome in ze...  autosomal dominant   \n",
       "2  Clinical perspective of afatinib in non-small ...   EGFR-mutant NSCLC   \n",
       "3  DOCA sensitive pendrin expression in kidney, h...             thyroid   \n",
       "4  Clinical and molecular characteristics of Pend...             thyroid   \n",
       "\n",
       "   answer_start  answer_end  \n",
       "0           213         231  \n",
       "1           105         123  \n",
       "2          1203        1220  \n",
       "3           419         426  \n",
       "4           705         712  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5938b111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12988, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset = [\"context\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2582, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8683b999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.question.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b0ddc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2582"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.context.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "383b90c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question        What is the characteristic feature of the Dyke...\n",
       "context         Left hemisphere and male sex dominance of cere...\n",
       "answer_text                                  cerebral hemiatrophy\n",
       "answer_start                                                  130\n",
       "answer_end                                                    150\n",
       "Name: 240, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_question = df.iloc[240]\n",
    "sample_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82ac253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_answer(question):\n",
    "    answer_start, answer_end = question[\"answer_start\"], question[\"answer_end\"]\n",
    "    context = question[\"context\"]\n",
    "    \n",
    "    return colored(context[:answer_start], \"yellow\") + \\\n",
    "            colored(context[answer_start:answer_end + 1], \"green\") + \\\n",
    "            colored(context[answer_end + 1:], \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fd18eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the characteristic feature of the Dyke-Davidoff-Masson syndrome.\n",
      "\n",
      "Answer : \n",
      "\u001b[33mLeft hemisphere and male sex dominance of cerebral hemiatrophy (Dyke-Davidoff-Masson Syndrome). Although\n",
      "radiological findings of \u001b[0m\u001b[32mcerebral hemiatrophy \u001b[0m\u001b[34m(Dyke-Davidoff-Masson Syndrome) are well known, there is\n",
      "no systematic study about the gender and the affected side in this syndrome. Brain images in 26 patients (mean aged 11)\n",
      "with cerebral hemiatrophy were retrospectively reviewed. Nineteen patients (73.5%) were male and seven patients (26.5%)\n",
      "were female. Left hemisphere involvement was seen in 18 patients (69.2%) and right hemisphere involvement was seen in\n",
      "eight patients (30.8%). We conclude that male gender and left side involvement are frequent in cerebral hemiatrophy\n",
      "disease.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(sample_question[\"question\"])\n",
    "print()\n",
    "print(\"Answer : \")\n",
    "\n",
    "for wrap in textwrap.wrap(color_answer(sample_question), width = 120):\n",
    "    print(wrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 't5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2cecc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c573634",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_encoding = tokenizer(\"Would I rather be loved or feared?\",\"Easy. Both. I want people be afraid of how much they love me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fe19bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(sample_encoding.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54e55e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5328, 27, 1066, 36, 1858, 42, 3, 27625, 58, 1, 6844, 5, 2867, 5, 27, 241, 151, 36, 7403, 13, 149, 231, 79, 333, 140, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "print(sample_encoding[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c50b85df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(sample_encoding[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6d5c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\n",
    "    tokenizer.decode(input_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    for input_id in sample_encoding[\"input_ids\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f319247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would I rather be loved or  feared ? </s> Easy . Both . I want people be afraid of how much they love me . </s>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b27c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(sample_question[\"question\"],sample_question[\"context\"], max_length = 396, padding = \"max_length\", \n",
    "          truncation = \"only_second\", return_attention_mask=True, add_special_tokens=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "114f5110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a63ff6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'pad_token': '<pad>',\n",
       " 'additional_special_tokens': \"['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']\"}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f7642fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('</s>', 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token, tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e914e957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the characteristic feature of the Dyke-Davidoff-Masson syndrome.</s> Left hemisphere and male sex dominance of cerebral hemiatrophy (Dyke-Davidoff-Masson Syndrome). Although radiological findings of cerebral hemiatrophy (Dyke-Davidoff-Masson Syndrome) are well known, there is no systematic study about the gender and the affected side in this syndrome. Brain images in 26 patients (mean aged 11) with cerebral hemiatrophy were retrospectively reviewed. Nineteen patients (73.5%) were male and seven patients (26.5%) were female. Left hemisphere involvement was seen in 18 patients (69.2%) and right hemisphere involvement was seen in eight patients (30.8%). We conclude that male gender and left side involvement are frequent in cerebral hemiatrophy disease.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding[\"input_ids\"].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85705f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_encoding = tokenizer(\n",
    "     sample_question['answer_text'],\n",
    "     max_length=32,\n",
    "     padding='max_length',\n",
    "     truncation=True,\n",
    "     return_attention_mask=True,\n",
    "     add_special_tokens=True,\n",
    "     return_tensors=\"pt\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31d54acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cerebral hemiatrophy</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(answer_encoding['input_ids'].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c408d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = answer_encoding[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f50386d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24387,     3,   107, 11658,    17, 29006,     1,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5edc7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[labels == 0] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02d9bb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24387,     3,   107, 11658,    17, 29006,     1,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c8ca551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioAQDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data:pd.DataFrame, tokenizer:T5Tokenizer, source_max_token_len: int =369, target_max_token_len: int =32):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        \n",
    "        data_row = self.data.iloc[index]\n",
    "        \n",
    "        source_encoding = tokenizer(data_row['question'], data_row['context'], max_length=self.source_max_token_len,\n",
    "                                        padding='max_length', truncation=\"only_second\", return_attention_mask=True,\n",
    "                                        add_special_tokens=True, return_tensors=\"pt\")\n",
    "        \n",
    "        target_encoding = tokenizer(data_row['answer_text'], max_length=self.target_max_token_len, padding='max_length',\n",
    "                                        truncation=True, return_attention_mask=True, add_special_tokens=True,\n",
    "                                        return_tensors=\"pt\")\n",
    "        \n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return dict(question = data_row[\"question\"], context = data_row[\"context\"], answer_text = data_row[\"answer_text\"],\n",
    "                       input_ids = source_encoding[\"input_ids\"].flatten(), \n",
    "                       attention_mask = source_encoding[\"attention_mask\"].flatten(), labels = labels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed91aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = BioAQDataset(df,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b5edb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  What is the inheritance pattern of Li–Fraumeni syndrome?\n",
      "answers:  autosomal dominant\n",
      "input_ids:  tensor([  363,    19,     8, 28915,  3275,    13,  1414,   104,   371,  6340])\n",
      "labels:  tensor([ 1510, 10348,   138, 12613,     1,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "for data in sample_dataset:\n",
    "    print(\"question: \", data[\"question\"])\n",
    "    print(\"answers: \",data[\"answer_text\"])\n",
    "    print(\"input_ids: \", data[\"input_ids\"][:10])\n",
    "    print(\"labels: \", data[\"labels\"][:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d094b0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51b90f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2452, 5)\n",
      "(130, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6cb38dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df: pd.DataFrame, test_df: pd.DataFrame, tokenizer:T5Tokenizer, batch_size: int = 8,\n",
    "                    source_max_token_len: int = 396, target_max_token_len: int = 32):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "   \n",
    "    def setup(self):\n",
    "        \n",
    "        self.train_dataset = BioAQDataset(self.train_df, self.tokenizer, self.source_max_token_len, self.target_max_token_len)\n",
    "        \n",
    "        self.test_dataset = BioAQDataset(self.test_df, self.tokenizer, self.source_max_token_len, self.target_max_token_len)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=4)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d23bc0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "N_EPOCHS = 6\n",
    "\n",
    "data_module = BioDataModule(train_df, val_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0c666ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52c131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids=encoding[\"input_ids\"], attention_mask=encoding[\"attention_mask\"], labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "584e3c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32128])\n"
     ]
    }
   ],
   "source": [
    "print(output.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff1ffd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0636, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "094c531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioQAModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "   \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        \n",
    "        output = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return output.loss, output.logits\n",
    "   \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\":outputs, \"labels\": labels}\n",
    "       \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask=batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=0.0001)\n",
    "        return optimizer      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "27b747a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-base were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BioQAModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a3ac198",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoints\", filename=\"best-checkpoint\",filepath=\"./\", save_top_k=1, verbose=True,\n",
    "                                        monitor=\"val_loss\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2dd64375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/ankitk/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(checkpoint_callback=checkpoint_callback, max_epochs=N_EPOCHS, progress_bar_refresh_rate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "46ce5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "22930e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2466), started 3:21:13 ago. (Use '!kill 2466' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e3e70682c2094cac\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e3e70682c2094cac\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2bb54d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "-----------------------------------------------------\n",
      "222 M     Trainable params\n",
      "0         Non-trainable params\n",
      "222 M     Total params\n",
      "891.614   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2ceb7520f449a39d847d6ca024103a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afedf1d1cba64416ae9f6ca4c77a54b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60dc839d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'best_model_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-24edee734c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, test_dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__test_given_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__test_using_best_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__test_using_best_weights\u001b[0;34m(self, ckpt_path, test_dataloaders)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;31m# if user requests the best checkpoint but we don't have it, error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'best'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m             raise MisconfigurationException(\n\u001b[1;32m    924\u001b[0m                 \u001b[0;34m'ckpt_path is \"best\", but ModelCheckpoint is not configured to save the best model.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'best_model_path'"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249132d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = BioQAModel.load_from_checkpoint(\"checkpoints/best-checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64dc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ded47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2c2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c5847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe37658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b9c01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ebfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ad149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    source_encoding=tokenizer(\n",
    "            question[\"question\"],\n",
    "            question['context'],\n",
    "            max_length = 396,\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"only_second\",\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "       )\n",
    "    \n",
    "    generated_ids = trained_model.model.generate(\n",
    "            input_ids=source_encoding[\"input_ids\"],\n",
    "            attention_mask=source_encoding[\"attention_mask\"],\n",
    "            num_beams=1,  # greedy search\n",
    "            max_length=80,\n",
    "            repetition_penalty=2.5,\n",
    "            early_stopping=True,\n",
    "            use_cache=True)\n",
    "       \n",
    "    preds = [\n",
    "               tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "               for generated_id in generated_ids\n",
    "            ]\n",
    "    \n",
    "    return \"\".join(preds)\n",
    "     \n",
    "    sample_question = val_df.iloc[20]\n",
    "    sample_question[\"question\"]  \n",
    "    sample_question[\"answer_text\"]  # Label Answer\n",
    "    generate_answer(sample_question)  # Predicted answer\n",
    "    sample_question = val_df.iloc[66]\n",
    "    sample_question[\"answer_text\"]\n",
    "    generate_answer(sample_question) \n",
    "\n",
    "    #mkdir zip\n",
    "    \n",
    "    !zip -r /content.zip /content\n",
    "    \n",
    "    from google.colab import files\n",
    "        files.download(\"/content.zip\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp2021]",
   "language": "python",
   "name": "conda-env-nlp2021-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
